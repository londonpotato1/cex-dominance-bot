"""ìƒì¥ ë³µê¸° ìë™í™” ëª¨ë“ˆ (Phase 8 Week 4).

ìƒì¥ í›„ ë°ì´í„°ë¥¼ ìë™ ìˆ˜ì§‘í•˜ê³  í¥/ë§ íŒì •.

í¥/ë§ íŒì • ê¸°ì¤€ (DDARI_FUNDAMENTALS.md ê¸°ì¤€):
- ì†ë°”ë€œ ë¹„ìœ¨ = ê±°ë˜ëŸ‰ / ì…ê¸ˆì•¡
- 5ë°° ì´ìƒ â†’ ëŒ€í¥ë”°ë¦¬
- 3ë°° ì´ìƒ â†’ í¥ë”°ë¦¬ 
- 1~3ë°° â†’ ë³´í†µ
- 1ë°° ì´í•˜ â†’ ë§ë”°ë¦¬

ìˆ˜ì§‘ ë°ì´í„°:
- 5ë¶„ ê±°ë˜ëŸ‰ (volume_5m_krw)
- 1ë¶„ ê±°ë˜ëŸ‰ (volume_1m_krw)
- ìµœê³  í”„ë¦¬ë¯¸ì—„ (max_premium_pct)
- ì…ê¸ˆì•¡ ì¶”ì • (deposit_krw)
- ì‹œì´ ìƒìŠ¹ë¶„ (market_cap_change_pct)
"""

from __future__ import annotations

import csv
import logging
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Optional

logger = logging.getLogger(__name__)

# CSV íŒŒì¼ ê²½ë¡œ
LISTING_DATA_PATH = Path(__file__).parent.parent / "data" / "labeling" / "listing_data.csv"


class ResultLabel(Enum):
    """ìƒì¥ ê²°ê³¼ ë¼ë²¨."""
    MEGA_SUCCESS = "ëŒ€í¥ë”°ë¦¬"      # ì†ë°”ë€œ 5ë°°+
    SUCCESS = "í¥ë”°ë¦¬"             # ì†ë°”ë€œ 3~5ë°°
    NORMAL = "ë³´í†µ"                # ì†ë°”ë€œ 1~3ë°°
    FAIL = "ë§ë”°ë¦¬"                # ì†ë°”ë€œ 1ë°° ì´í•˜


@dataclass
class ListingReviewData:
    """ìƒì¥ ë³µê¸° ë°ì´í„°."""
    # ê¸°ë³¸ ì •ë³´
    symbol: str
    exchange: str
    date: str  # YYYY-MM-DD
    listing_type: str  # TGE, ì§ìƒì¥, ì˜†ìƒì¥
    
    # ì‹œì¥ ë°ì´í„°
    market_cap_usd: Optional[float] = None
    top_exchange: Optional[str] = None
    top_exchange_tier: Optional[str] = None
    
    # í•µì‹¬ ì§€í‘œ
    deposit_krw: Optional[float] = None           # ì…ê¸ˆì•¡ (ì›)
    volume_5m_krw: Optional[float] = None         # 5ë¶„ ê±°ë˜ëŸ‰ (ì›)
    volume_1m_krw: Optional[float] = None         # 1ë¶„ ê±°ë˜ëŸ‰ (ì›)
    turnover_ratio: Optional[float] = None        # ì†ë°”ë€œ ë¹„ìœ¨
    max_premium_pct: Optional[float] = None       # ìµœê³  í”„ë¦¬ë¯¸ì—„ (%)
    premium_at_5m_pct: Optional[float] = None     # 5ë¶„ ì‹œì  í”„ë¦¬ë¯¸ì—„ (%)
    
    # ê³µê¸‰ ë¶„ì„
    supply_label: Optional[str] = None            # constrained, smooth
    hedge_type: Optional[str] = None              # cex_futures, dex_futures, none
    dex_liquidity_usd: Optional[float] = None
    hot_wallet_usd: Optional[float] = None
    network_chain: Optional[str] = None
    network_speed_min: Optional[float] = None
    withdrawal_open: Optional[bool] = None
    airdrop_claim_rate: Optional[float] = None
    
    # ì‹œí™©
    prev_listing_result: Optional[str] = None
    market_condition: Optional[str] = None        # bull, bear, neutral
    
    # ê²°ê³¼
    result_label: Optional[str] = None
    result_notes: Optional[str] = None


class ListingResultClassifier:
    """í¥/ë§ íŒì • ë¶„ë¥˜ê¸°.
    
    ì†ë°”ë€œ ë¹„ìœ¨ ê¸°ë°˜ ìë™ ë¶„ë¥˜:
    - ì†ë°”ë€œ ë¹„ìœ¨ = ê±°ë˜ëŸ‰ / ì…ê¸ˆì•¡
    - 5ë°° ì´ìƒ â†’ ëŒ€í¥ë”°ë¦¬
    - 3ë°° ì´ìƒ â†’ í¥ë”°ë¦¬
    - 1~3ë°° â†’ ë³´í†µ
    - 1ë°° ì´í•˜ â†’ ë§ë”°ë¦¬
    """
    
    # ì†ë°”ë€œ ë¹„ìœ¨ ê¸°ì¤€
    MEGA_SUCCESS_THRESHOLD = 5.0   # 5ë°° ì´ìƒ: ëŒ€í¥ë”°ë¦¬
    SUCCESS_THRESHOLD = 3.0        # 3ë°° ì´ìƒ: í¥ë”°ë¦¬
    NORMAL_THRESHOLD = 1.0         # 1ë°° ì´ìƒ: ë³´í†µ
    # 1ë°° ë¯¸ë§Œ: ë§ë”°ë¦¬
    
    def classify(
        self,
        volume_krw: float,
        deposit_krw: float,
        max_premium_pct: Optional[float] = None,
    ) -> tuple[ResultLabel, float, str]:
        """í¥/ë§ íŒì •.
        
        Args:
            volume_krw: 5ë¶„ ê±°ë˜ëŸ‰ (ì›)
            deposit_krw: ì…ê¸ˆì•¡ ì¶”ì • (ì›)
            max_premium_pct: ìµœê³  í”„ë¦¬ë¯¸ì—„ (%) - ë³´ì¡° ì§€í‘œ
            
        Returns:
            (ResultLabel, turnover_ratio, reason)
        """
        if deposit_krw <= 0:
            logger.warning("ì…ê¸ˆì•¡ì´ 0 ì´í•˜ì…ë‹ˆë‹¤. ë¶„ë¥˜ ë¶ˆê°€.")
            return ResultLabel.NORMAL, 0.0, "ì…ê¸ˆì•¡ ë°ì´í„° ì—†ìŒ"
        
        # ì†ë°”ë€œ ë¹„ìœ¨ ê³„ì‚°
        turnover_ratio = volume_krw / deposit_krw
        
        # ê¸°ë³¸ ë¶„ë¥˜
        if turnover_ratio >= self.MEGA_SUCCESS_THRESHOLD:
            label = ResultLabel.MEGA_SUCCESS
            reason = f"ì†ë°”ë€œ {turnover_ratio:.1f}ë°° (5ë°°+)"
        elif turnover_ratio >= self.SUCCESS_THRESHOLD:
            label = ResultLabel.SUCCESS
            reason = f"ì†ë°”ë€œ {turnover_ratio:.1f}ë°° (3~5ë°°)"
        elif turnover_ratio >= self.NORMAL_THRESHOLD:
            label = ResultLabel.NORMAL
            reason = f"ì†ë°”ë€œ {turnover_ratio:.1f}ë°° (1~3ë°°)"
        else:
            label = ResultLabel.FAIL
            reason = f"ì†ë°”ë€œ {turnover_ratio:.1f}ë°° (1ë°° ë¯¸ë§Œ)"
        
        # í”„ë¦¬ë¯¸ì—„ ë³´ì¡° ì§€í‘œ ë°˜ì˜
        if max_premium_pct is not None:
            if max_premium_pct >= 100 and label != ResultLabel.MEGA_SUCCESS:
                # ê¹€í”„ 100%+ ì¸ë° ëŒ€í¥ë”°ë¦¬ ì•„ë‹Œ ê²½ìš° â†’ ì—…ê·¸ë ˆì´ë“œ ê³ ë ¤
                reason += f", ìµœê³ ê¹€í”„ {max_premium_pct:.0f}%"
            elif max_premium_pct <= 0 and label not in (ResultLabel.FAIL, ResultLabel.NORMAL):
                # ì—­í”„ì¸ë° í¥ë”°ë¦¬ì¸ ê²½ìš° â†’ ë‹¤ìš´ê·¸ë ˆì´ë“œ ê³ ë ¤
                reason += f", âš ï¸ ì—­í”„ ë°œìƒ"
        
        return label, turnover_ratio, reason
    
    def classify_from_data(self, data: ListingReviewData) -> tuple[ResultLabel, str]:
        """ListingReviewDataë¡œë¶€í„° ë¶„ë¥˜.
        
        Returns:
            (ResultLabel, reason)
        """
        if data.volume_5m_krw is None or data.deposit_krw is None:
            return ResultLabel.NORMAL, "ë°ì´í„° ë¶€ì¡±"
        
        label, turnover_ratio, reason = self.classify(
            volume_krw=data.volume_5m_krw,
            deposit_krw=data.deposit_krw,
            max_premium_pct=data.max_premium_pct,
        )
        
        # turnover_ratio ì—…ë°ì´íŠ¸
        data.turnover_ratio = turnover_ratio
        
        return label, reason


class ListingDataStore:
    """listing_data.csv ê´€ë¦¬."""
    
    # CSV ì»¬ëŸ¼ ìˆœì„œ (ê¸°ì¡´ í˜•ì‹ ìœ ì§€)
    COLUMNS = [
        "symbol", "exchange", "date", "listing_type",
        "market_cap_usd", "top_exchange", "top_exchange_tier",
        "deposit_krw", "volume_5m_krw", "volume_1m_krw",
        "turnover_ratio", "max_premium_pct", "premium_at_5m_pct",
        "supply_label", "hedge_type", "dex_liquidity_usd", "hot_wallet_usd",
        "network_chain", "network_speed_min", "withdrawal_open",
        "airdrop_claim_rate", "prev_listing_result", "market_condition",
        "result_label", "result_notes",
    ]
    
    def __init__(self, csv_path: Path = LISTING_DATA_PATH) -> None:
        self.csv_path = csv_path
    
    def load_all(self) -> list[ListingReviewData]:
        """ëª¨ë“  ë°ì´í„° ë¡œë“œ."""
        if not self.csv_path.exists():
            logger.warning(f"CSV íŒŒì¼ ì—†ìŒ: {self.csv_path}")
            return []
        
        results = []
        with open(self.csv_path, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                data = self._row_to_data(row)
                results.append(data)
        
        logger.info(f"ë¡œë“œ ì™„ë£Œ: {len(results)}ê±´")
        return results
    
    def find(self, symbol: str, exchange: str, date: Optional[str] = None) -> Optional[ListingReviewData]:
        """íŠ¹ì • ìƒì¥ ë°ì´í„° ì°¾ê¸°."""
        all_data = self.load_all()
        for data in all_data:
            if data.symbol == symbol and data.exchange == exchange:
                if date is None or data.date == date:
                    return data
        return None
    
    def save(self, data: ListingReviewData, update_existing: bool = True) -> bool:
        """ë°ì´í„° ì €ì¥ (ì¶”ê°€ ë˜ëŠ” ì—…ë°ì´íŠ¸).
        
        Args:
            data: ì €ì¥í•  ë°ì´í„°
            update_existing: Trueë©´ ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸, Falseë©´ ì¤‘ë³µ ë¬´ì‹œ
            
        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        all_data = self.load_all()
        
        # ê¸°ì¡´ ë°ì´í„° ì°¾ê¸°
        existing_idx = None
        for i, existing in enumerate(all_data):
            if (existing.symbol == data.symbol and 
                existing.exchange == data.exchange and
                (existing.date == data.date or not existing.date or not data.date)):
                existing_idx = i
                break
        
        if existing_idx is not None:
            if update_existing:
                all_data[existing_idx] = data
                logger.info(f"ì—…ë°ì´íŠ¸: {data.symbol}@{data.exchange}")
            else:
                logger.info(f"ì¤‘ë³µ ìŠ¤í‚µ: {data.symbol}@{data.exchange}")
                return False
        else:
            all_data.append(data)
            logger.info(f"ì¶”ê°€: {data.symbol}@{data.exchange}")
        
        # CSV ì €ì¥
        self._save_all(all_data)
        return True
    
    def _save_all(self, all_data: list[ListingReviewData]) -> None:
        """ì „ì²´ ë°ì´í„° CSV ì €ì¥."""
        # ë¶€ëª¨ ë””ë ‰í† ë¦¬ ìƒì„±
        self.csv_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(self.csv_path, "w", encoding="utf-8", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=self.COLUMNS)
            writer.writeheader()
            for data in all_data:
                row = self._data_to_row(data)
                writer.writerow(row)
        
        logger.info(f"ì €ì¥ ì™„ë£Œ: {len(all_data)}ê±´ â†’ {self.csv_path}")
    
    def _row_to_data(self, row: dict) -> ListingReviewData:
        """CSV row â†’ ListingReviewData."""
        return ListingReviewData(
            symbol=row.get("symbol", ""),
            exchange=row.get("exchange", ""),
            date=row.get("date", ""),
            listing_type=row.get("listing_type", ""),
            market_cap_usd=self._parse_float(row.get("market_cap_usd")),
            top_exchange=row.get("top_exchange") or None,
            top_exchange_tier=row.get("top_exchange_tier") or None,
            deposit_krw=self._parse_float(row.get("deposit_krw")),
            volume_5m_krw=self._parse_float(row.get("volume_5m_krw")),
            volume_1m_krw=self._parse_float(row.get("volume_1m_krw")),
            turnover_ratio=self._parse_float(row.get("turnover_ratio")),
            max_premium_pct=self._parse_float(row.get("max_premium_pct")),
            premium_at_5m_pct=self._parse_float(row.get("premium_at_5m_pct")),
            supply_label=row.get("supply_label") or None,
            hedge_type=row.get("hedge_type") or None,
            dex_liquidity_usd=self._parse_float(row.get("dex_liquidity_usd")),
            hot_wallet_usd=self._parse_float(row.get("hot_wallet_usd")),
            network_chain=row.get("network_chain") or None,
            network_speed_min=self._parse_float(row.get("network_speed_min")),
            withdrawal_open=self._parse_bool(row.get("withdrawal_open")),
            airdrop_claim_rate=self._parse_float(row.get("airdrop_claim_rate")),
            prev_listing_result=row.get("prev_listing_result") or None,
            market_condition=row.get("market_condition") or None,
            result_label=row.get("result_label") or None,
            result_notes=row.get("result_notes") or None,
        )
    
    def _data_to_row(self, data: ListingReviewData) -> dict:
        """ListingReviewData â†’ CSV row."""
        return {
            "symbol": data.symbol,
            "exchange": data.exchange,
            "date": data.date or "",
            "listing_type": data.listing_type or "",
            "market_cap_usd": self._format_number(data.market_cap_usd),
            "top_exchange": data.top_exchange or "",
            "top_exchange_tier": data.top_exchange_tier or "",
            "deposit_krw": self._format_number(data.deposit_krw),
            "volume_5m_krw": self._format_number(data.volume_5m_krw),
            "volume_1m_krw": self._format_number(data.volume_1m_krw),
            "turnover_ratio": self._format_number(data.turnover_ratio, decimals=2),
            "max_premium_pct": self._format_number(data.max_premium_pct),
            "premium_at_5m_pct": self._format_number(data.premium_at_5m_pct),
            "supply_label": data.supply_label or "",
            "hedge_type": data.hedge_type or "",
            "dex_liquidity_usd": self._format_number(data.dex_liquidity_usd),
            "hot_wallet_usd": self._format_number(data.hot_wallet_usd),
            "network_chain": data.network_chain or "",
            "network_speed_min": self._format_number(data.network_speed_min),
            "withdrawal_open": str(data.withdrawal_open).lower() if data.withdrawal_open is not None else "",
            "airdrop_claim_rate": self._format_number(data.airdrop_claim_rate),
            "prev_listing_result": data.prev_listing_result or "",
            "market_condition": data.market_condition or "",
            "result_label": data.result_label or "",
            "result_notes": data.result_notes or "",
        }
    
    @staticmethod
    def _parse_float(value: Optional[str]) -> Optional[float]:
        """ë¬¸ìì—´ â†’ float."""
        if value is None or value == "":
            return None
        try:
            return float(value)
        except ValueError:
            return None
    
    @staticmethod
    def _parse_bool(value: Optional[str]) -> Optional[bool]:
        """ë¬¸ìì—´ â†’ bool."""
        if value is None or value == "":
            return None
        return value.lower() == "true"
    
    @staticmethod
    def _format_number(value: Optional[float], decimals: int = 0) -> str:
        """ìˆ«ì í¬ë§·íŒ…."""
        if value is None:
            return ""
        if decimals == 0:
            return str(int(value))
        return f"{value:.{decimals}f}"


class ListingReviewCollector:
    """ìƒì¥ í›„ ë°ì´í„° ìë™ ìˆ˜ì§‘ê¸°.
    
    ê±°ë˜ì†Œ APIë¥¼ í†µí•´ ìƒì¥ í›„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³ 
    ìë™ìœ¼ë¡œ í¥/ë§ íŒì •.
    """
    
    def __init__(self) -> None:
        self.classifier = ListingResultClassifier()
        self.store = ListingDataStore()
    
    def collect_and_classify(
        self,
        symbol: str,
        exchange: str,
        deposit_krw: float,
        volume_5m_krw: float,
        volume_1m_krw: Optional[float] = None,
        max_premium_pct: Optional[float] = None,
        premium_at_5m_pct: Optional[float] = None,
        market_cap_usd: Optional[float] = None,
        listing_type: str = "TGE",
        date: Optional[str] = None,
        notes: Optional[str] = None,
        **kwargs,
    ) -> ListingReviewData:
        """ìƒì¥ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ë¥˜.
        
        Args:
            symbol: í† í° ì‹¬ë³¼
            exchange: ê±°ë˜ì†Œ (Upbit, Bithumb)
            deposit_krw: ì…ê¸ˆì•¡ ì¶”ì • (ì›)
            volume_5m_krw: 5ë¶„ ê±°ë˜ëŸ‰ (ì›)
            volume_1m_krw: 1ë¶„ ê±°ë˜ëŸ‰ (ì›)
            max_premium_pct: ìµœê³  í”„ë¦¬ë¯¸ì—„ (%)
            premium_at_5m_pct: 5ë¶„ ì‹œì  í”„ë¦¬ë¯¸ì—„ (%)
            market_cap_usd: ì‹œê°€ì´ì•¡ (USD)
            listing_type: ìƒì¥ ìœ í˜• (TGE, ì§ìƒì¥, ì˜†ìƒì¥)
            date: ìƒì¥ì¼ (YYYY-MM-DD)
            notes: ë©”ëª¨
            **kwargs: ì¶”ê°€ í•„ë“œ
            
        Returns:
            ë¶„ë¥˜ëœ ListingReviewData
        """
        if date is None:
            date = datetime.now().strftime("%Y-%m-%d")
        
        # ë°ì´í„° ìƒì„±
        data = ListingReviewData(
            symbol=symbol.upper(),
            exchange=exchange,
            date=date,
            listing_type=listing_type,
            market_cap_usd=market_cap_usd,
            deposit_krw=deposit_krw,
            volume_5m_krw=volume_5m_krw,
            volume_1m_krw=volume_1m_krw,
            max_premium_pct=max_premium_pct,
            premium_at_5m_pct=premium_at_5m_pct,
        )
        
        # ì¶”ê°€ í•„ë“œ ì„¤ì •
        for key, value in kwargs.items():
            if hasattr(data, key):
                setattr(data, key, value)
        
        # í¥/ë§ ë¶„ë¥˜
        label, reason = self.classifier.classify_from_data(data)
        data.result_label = label.value
        
        # ë…¸íŠ¸ ì¶”ê°€
        if notes:
            data.result_notes = notes
        else:
            data.result_notes = reason
        
        logger.info(f"ë¶„ë¥˜ ì™„ë£Œ: {symbol}@{exchange} â†’ {label.value} ({reason})")
        
        return data
    
    def collect_classify_save(
        self,
        symbol: str,
        exchange: str,
        deposit_krw: float,
        volume_5m_krw: float,
        **kwargs,
    ) -> ListingReviewData:
        """ìˆ˜ì§‘ + ë¶„ë¥˜ + ì €ì¥ ì¼ê´„ ì²˜ë¦¬."""
        data = self.collect_and_classify(
            symbol=symbol,
            exchange=exchange,
            deposit_krw=deposit_krw,
            volume_5m_krw=volume_5m_krw,
            **kwargs,
        )
        
        self.store.save(data)
        return data
    
    def reclassify_all(self) -> dict[str, int]:
        """ëª¨ë“  ë°ì´í„° ì¬ë¶„ë¥˜.
        
        ê¸°ì¡´ CSVì˜ turnover_ratioê°€ ì—†ëŠ” í•­ëª©ë“¤ì„ 
        ë‹¤ì‹œ ê³„ì‚°í•˜ê³  result_label ì—…ë°ì´íŠ¸.
        
        Returns:
            {"updated": N, "skipped": M, "total": T}
        """
        all_data = self.store.load_all()
        updated = 0
        skipped = 0
        
        for data in all_data:
            if data.volume_5m_krw and data.deposit_krw:
                old_label = data.result_label
                label, reason = self.classifier.classify_from_data(data)
                new_label = label.value
                
                if old_label != new_label:
                    logger.info(f"ì¬ë¶„ë¥˜: {data.symbol}@{data.exchange} {old_label} â†’ {new_label}")
                    data.result_label = new_label
                    updated += 1
                else:
                    skipped += 1
            else:
                skipped += 1
        
        # ì €ì¥
        self.store._save_all(all_data)
        
        result = {
            "updated": updated,
            "skipped": skipped,
            "total": len(all_data),
        }
        logger.info(f"ì¬ë¶„ë¥˜ ì™„ë£Œ: {result}")
        return result


def analyze_listing_stats(csv_path: Path = LISTING_DATA_PATH) -> dict:
    """ìƒì¥ í†µê³„ ë¶„ì„.
    
    Returns:
        í†µê³„ ë”•ì…”ë„ˆë¦¬
    """
    store = ListingDataStore(csv_path)
    all_data = store.load_all()
    
    if not all_data:
        return {"error": "ë°ì´í„° ì—†ìŒ"}
    
    # ë¼ë²¨ë³„ ì§‘ê³„
    label_counts = {}
    for data in all_data:
        label = data.result_label or "ë¯¸ë¶„ë¥˜"
        label_counts[label] = label_counts.get(label, 0) + 1
    
    # ê±°ë˜ì†Œë³„ ì§‘ê³„
    exchange_counts = {}
    for data in all_data:
        ex = data.exchange or "Unknown"
        exchange_counts[ex] = exchange_counts.get(ex, 0) + 1
    
    # ìƒì¥ ìœ í˜•ë³„ ì§‘ê³„
    type_counts = {}
    for data in all_data:
        lt = data.listing_type or "ë¯¸ë¶„ë¥˜"
        type_counts[lt] = type_counts.get(lt, 0) + 1
    
    # ì†ë°”ë€œ ë¹„ìœ¨ í†µê³„
    turnover_ratios = [d.turnover_ratio for d in all_data if d.turnover_ratio]
    avg_turnover = sum(turnover_ratios) / len(turnover_ratios) if turnover_ratios else 0
    max_turnover = max(turnover_ratios) if turnover_ratios else 0
    min_turnover = min(turnover_ratios) if turnover_ratios else 0
    
    return {
        "total": len(all_data),
        "by_label": label_counts,
        "by_exchange": exchange_counts,
        "by_type": type_counts,
        "turnover_stats": {
            "avg": round(avg_turnover, 2),
            "max": round(max_turnover, 2),
            "min": round(min_turnover, 2),
            "count": len(turnover_ratios),
        },
    }


def format_review_report(data: ListingReviewData) -> str:
    """ìƒì¥ ë³µê¸° ë¦¬í¬íŠ¸ í¬ë§·."""
    lines = [
        f"ğŸ“Š **ìƒì¥ ë³µê¸°: {data.symbol}@{data.exchange}**",
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        f"ğŸ“… ì¼ì: {data.date or 'N/A'}",
        f"ğŸ“Œ ìœ í˜•: {data.listing_type or 'N/A'}",
        "",
        "**ğŸ“ˆ í•µì‹¬ ì§€í‘œ**",
    ]
    
    if data.deposit_krw:
        lines.append(f"ğŸ’° ì…ê¸ˆì•¡: â‚©{data.deposit_krw/1e8:.1f}ì–µ")
    if data.volume_5m_krw:
        lines.append(f"ğŸ“Š 5ë¶„ ê±°ë˜ëŸ‰: â‚©{data.volume_5m_krw/1e8:.1f}ì–µ")
    if data.volume_1m_krw:
        lines.append(f"âš¡ 1ë¶„ ê±°ë˜ëŸ‰: â‚©{data.volume_1m_krw/1e8:.1f}ì–µ")
    if data.turnover_ratio:
        lines.append(f"ğŸ”„ ì†ë°”ë€œ ë¹„ìœ¨: {data.turnover_ratio:.2f}ë°°")
    if data.max_premium_pct:
        lines.append(f"ğŸ¥¬ ìµœê³  ê¹€í”„: {data.max_premium_pct:.1f}%")
    
    lines.extend([
        "",
        "**ğŸ¯ íŒì •**",
    ])
    
    # ë¼ë²¨ ì´ëª¨ì§€
    label_emoji = {
        "ëŒ€í¥ë”°ë¦¬": "ğŸš€",
        "í¥ë”°ë¦¬": "ğŸ“ˆ",
        "ë³´í†µ": "â–",
        "ë§ë”°ë¦¬": "ğŸ“‰",
    }
    emoji = label_emoji.get(data.result_label or "", "â“")
    lines.append(f"{emoji} **{data.result_label or 'ë¯¸ë¶„ë¥˜'}**")
    
    if data.result_notes:
        lines.append(f"ğŸ“ {data.result_notes}")
    
    return "\n".join(lines)


# CLIìš© ê°„í¸ í•¨ìˆ˜ë“¤
def review(
    symbol: str,
    exchange: str,
    deposit: float,
    volume_5m: float,
    **kwargs,
) -> str:
    """ìƒì¥ ë³µê¸° ê°„í¸ í•¨ìˆ˜.
    
    ì‚¬ìš©ë²•:
        from analysis.listing_review import review
        print(review("ERA", "Upbit", 205e8, 910e8, max_premium_pct=50))
    """
    collector = ListingReviewCollector()
    data = collector.collect_classify_save(
        symbol=symbol,
        exchange=exchange,
        deposit_krw=deposit,
        volume_5m_krw=volume_5m,
        **kwargs,
    )
    return format_review_report(data)


def stats() -> dict:
    """í†µê³„ ê°„í¸ í•¨ìˆ˜."""
    return analyze_listing_stats()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    logging.basicConfig(level=logging.INFO)
    
    # í†µê³„ ì¶œë ¥
    print("\n=== ìƒì¥ í†µê³„ ===")
    stats_result = analyze_listing_stats()
    for key, value in stats_result.items():
        print(f"{key}: {value}")
    
    # ì˜ˆì‹œ: ERA ë³µê¸°
    print("\n=== ERA ë³µê¸° ì˜ˆì‹œ ===")
    result = review(
        symbol="TEST",
        exchange="Upbit",
        deposit=20.5e9,  # 205ì–µ
        volume_5m=91e9,   # 910ì–µ
        max_premium_pct=50,
        listing_type="TGE",
        notes="í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°",
    )
    print(result)
