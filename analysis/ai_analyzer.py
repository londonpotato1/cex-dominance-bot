"""AI ê¸°ë°˜ ê³µì‹œ ë¶„ì„ ëª¨ë“ˆ (Phase 3).

Claude APIë¥¼ ì‚¬ìš©í•´ì„œ ê³µì‹œ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê³ ,
ë£° ê¸°ë°˜ ë¶„ì„ ê²°ê³¼ì™€ í¬ë¡œìŠ¤ì²´í¬í•©ë‹ˆë‹¤.

ë¹„ìš© ì ˆê°:
  - ê¸°ë³¸: claude-3-haiku (ë¹ ë¥´ê³  ì €ë ´)
  - ë³µì¡í•œ ë¶„ì„: claude-3-sonnet (ì •í™•ë„ ë†’ìŒ)
  
í™˜ê²½ë³€ìˆ˜:
  - ANTHROPIC_API_KEY: Claude API í‚¤
  - AI_ANALYZER_ENABLED: true/false (ê¸°ë³¸ true)
"""

from __future__ import annotations

import json
import logging
import os
from dataclasses import dataclass
from enum import Enum
from typing import Optional

logger = logging.getLogger(__name__)

# API í‚¤ í™•ì¸
_API_KEY = os.environ.get("ANTHROPIC_API_KEY")
_ENABLED = os.environ.get("AI_ANALYZER_ENABLED", "true").lower() == "true"

# ëª¨ë¸ ì„¤ì •
MODEL_FAST = "claude-3-haiku-20240307"  # ë¹ ë¥´ê³  ì €ë ´
MODEL_SMART = "claude-3-5-sonnet-20241022"  # ì •í™•ë„ ë†’ìŒ


class ListingRisk(Enum):
    """ìƒì¥ ë¦¬ìŠ¤í¬ ë ˆë²¨."""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class SupplyPressure(Enum):
    """ê³µê¸‰ ì••ë ¥."""
    SMOOTH = "smooth"      # ì›í™œ (í¥ë”°ë¦¬ ìœ ë ¥)
    MODERATE = "moderate"  # ë³´í†µ
    TIGHT = "tight"        # ê³µê¸‰ ì••ë°• (ë§ë”°ë¦¬ ì£¼ì˜)
    UNKNOWN = "unknown"


@dataclass
class AIAnalysisResult:
    """AI ë¶„ì„ ê²°ê³¼."""
    
    # ìƒì¥ ìœ í˜•
    listing_type: str  # TGE, DIRECT, SIDE
    listing_type_confidence: float  # 0.0 ~ 1.0
    
    # ë¦¬ìŠ¤í¬ í‰ê°€
    risk_level: ListingRisk
    risk_factors: list[str]
    
    # ê³µê¸‰ ì••ë ¥
    supply_pressure: SupplyPressure
    supply_reasoning: str
    
    # AI ì¸ì‚¬ì´íŠ¸
    summary: str  # í•œ ì¤„ ìš”ì•½
    warnings: list[str]  # ì£¼ì˜ì‚¬í•­
    
    # ë©”íƒ€
    model_used: str
    tokens_used: int
    analysis_time_ms: float
    
    # ì›ë³¸ ì‘ë‹µ
    raw_response: Optional[dict] = None


class AIAnalyzer:
    """Claude ê¸°ë°˜ ê³µì‹œ ë¶„ì„ê¸°."""
    
    def __init__(self, api_key: str | None = None):
        """
        Args:
            api_key: Anthropic API í‚¤. Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©.
        """
        self._api_key = api_key or _API_KEY
        self._client = None
        
        if not self._api_key:
            logger.warning("[AIAnalyzer] API í‚¤ ì—†ìŒ - AI ë¶„ì„ ë¹„í™œì„±í™”")
        elif not _ENABLED:
            logger.info("[AIAnalyzer] AI ë¶„ì„ ë¹„í™œì„±í™”ë¨ (AI_ANALYZER_ENABLED=false)")
    
    @property
    def is_available(self) -> bool:
        """AI ë¶„ì„ ê°€ëŠ¥ ì—¬ë¶€."""
        return bool(self._api_key and _ENABLED)
    
    def _get_client(self):
        """Anthropic í´ë¼ì´ì–¸íŠ¸ lazy ì´ˆê¸°í™”."""
        if self._client is None:
            try:
                from anthropic import Anthropic
                self._client = Anthropic(api_key=self._api_key)
            except ImportError:
                logger.error("[AIAnalyzer] anthropic íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜")
                return None
            except Exception as e:
                logger.error("[AIAnalyzer] í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: %s", e)
                return None
        return self._client
    
    async def analyze_announcement(
        self,
        text: str,
        exchange: str,
        symbol: str | None = None,
        use_smart_model: bool = False,
    ) -> AIAnalysisResult | None:
        """ê³µì‹œ í…ìŠ¤íŠ¸ ë¶„ì„.
        
        Args:
            text: ê³µì‹œ í…ìŠ¤íŠ¸ (HTML ë˜ëŠ” plain text).
            exchange: ê±°ë˜ì†Œ (upbit, bithumb).
            symbol: í† í° ì‹¬ë³¼ (ì•Œë©´).
            use_smart_model: Trueë©´ Sonnet ì‚¬ìš© (ë” ì •í™•).
            
        Returns:
            AIAnalysisResult ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ).
        """
        if not self.is_available:
            return None
        
        import time
        t0 = time.monotonic()
        
        client = self._get_client()
        if not client:
            return None
        
        model = MODEL_SMART if use_smart_model else MODEL_FAST
        
        prompt = self._build_prompt(text, exchange, symbol)
        
        try:
            response = client.messages.create(
                model=model,
                max_tokens=1024,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                system=self._system_prompt(),
            )
            
            duration_ms = (time.monotonic() - t0) * 1000
            
            # ì‘ë‹µ íŒŒì‹±
            content = response.content[0].text
            result = self._parse_response(content, model, response.usage.input_tokens + response.usage.output_tokens, duration_ms)
            
            logger.info(
                "[AIAnalyzer] ë¶„ì„ ì™„ë£Œ: %s@%s, risk=%s, supply=%s, %.0fms",
                symbol or "?", exchange, result.risk_level.value, 
                result.supply_pressure.value, duration_ms
            )
            
            return result
            
        except Exception as e:
            logger.error("[AIAnalyzer] ë¶„ì„ ì‹¤íŒ¨: %s", e)
            return None
    
    def analyze_announcement_sync(
        self,
        text: str,
        exchange: str,
        symbol: str | None = None,
        use_smart_model: bool = False,
    ) -> AIAnalysisResult | None:
        """ê³µì‹œ í…ìŠ¤íŠ¸ ë¶„ì„ (ë™ê¸° ë²„ì „)."""
        import asyncio
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(
            self.analyze_announcement(text, exchange, symbol, use_smart_model)
        )
    
    async def cross_check(
        self,
        rule_result: dict,
        ai_result: AIAnalysisResult,
    ) -> dict:
        """ë£° ê¸°ë°˜ ê²°ê³¼ì™€ AI ê²°ê³¼ í¬ë¡œìŠ¤ì²´í¬.
        
        Args:
            rule_result: ë£° ê¸°ë°˜ Gate ë¶„ì„ ê²°ê³¼.
            ai_result: AI ë¶„ì„ ê²°ê³¼.
            
        Returns:
            dict: {
                "agreement": bool,  # ì¼ì¹˜ ì—¬ë¶€
                "confidence": float,  # ìµœì¢… ì‹ ë¢°ë„
                "warnings": list[str],  # ë¶ˆì¼ì¹˜ ê²½ê³ 
                "recommendation": str,  # ìµœì¢… ì¶”ì²œ
            }
        """
        warnings = []
        
        # 1. GO/NO-GO ì¼ì¹˜ í™•ì¸
        rule_go = rule_result.get("can_proceed", False)
        ai_risk = ai_result.risk_level
        
        # AIê°€ HIGH/CRITICAL ë¦¬ìŠ¤í¬ì¸ë° ë£°ì´ GOë©´ ê²½ê³ 
        if rule_go and ai_risk in (ListingRisk.HIGH, ListingRisk.CRITICAL):
            warnings.append(f"âš ï¸ AI ê²½ê³ : {ai_risk.value} ë¦¬ìŠ¤í¬ ê°ì§€")
        
        # 2. ê³µê¸‰ ì••ë ¥ ë¹„êµ
        rule_supply = rule_result.get("supply_classification", "unknown")
        ai_supply = ai_result.supply_pressure
        
        # ë¶ˆì¼ì¹˜ ì‹œ ê²½ê³ 
        if "smooth" in str(rule_supply).lower() and ai_supply == SupplyPressure.TIGHT:
            warnings.append("âš ï¸ AI: ê³µê¸‰ ì••ë°• ì˜ˆìƒ (ë£°ê³¼ ë¶ˆì¼ì¹˜)")
        elif "tight" in str(rule_supply).lower() and ai_supply == SupplyPressure.SMOOTH:
            warnings.append("ğŸ’¡ AI: ê³µê¸‰ ì›í™œ ì˜ˆìƒ (ë£°ê³¼ ë¶ˆì¼ì¹˜)")
        
        # 3. AI ê²½ê³ ì‚¬í•­ ì¶”ê°€
        for w in ai_result.warnings[:2]:
            warnings.append(f"ğŸ¤– {w}")
        
        # 4. ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
        rule_confidence = rule_result.get("confidence", 0.7)
        ai_confidence = ai_result.listing_type_confidence
        
        # ê°€ì¤‘ í‰ê·  (ë£° 60%, AI 40%)
        final_confidence = rule_confidence * 0.6 + ai_confidence * 0.4
        
        # ë¶ˆì¼ì¹˜ê°€ ë§ìœ¼ë©´ ì‹ ë¢°ë„ ê°ì†Œ
        if len(warnings) > 2:
            final_confidence *= 0.8
        
        # 5. ìµœì¢… ì¶”ì²œ
        if rule_go and not warnings:
            recommendation = "GO - ë£°/AI ì¼ì¹˜"
        elif rule_go and warnings:
            recommendation = "GO - ì£¼ì˜ í•„ìš” (AI ê²½ê³ )"
        else:
            recommendation = "NO-GO"
        
        return {
            "agreement": len(warnings) == 0,
            "confidence": round(final_confidence, 2),
            "warnings": warnings,
            "recommendation": recommendation,
            "ai_summary": ai_result.summary,
        }
    
    def _system_prompt(self) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸."""
        return """ë‹¹ì‹ ì€ ì•”í˜¸í™”í ê±°ë˜ì†Œ ìƒì¥ ê³µì‹œë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ê³µì‹œë¥¼ ë¶„ì„í•˜ê³  ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:

1. listing_type: ìƒì¥ ìœ í˜•
   - "TGE": ì‹ ê·œ í† í° ë°œí–‰ (Token Generation Event)
   - "DIRECT": í•´ì™¸ ë¨¼ì € ìƒì¥ëœ í† í°ì˜ êµ­ë‚´ ì§ìƒì¥
   - "SIDE": ë‹¤ë¥¸ êµ­ë‚´ ê±°ë˜ì†Œì—ì„œ ì´ë¯¸ ìƒì¥ëœ í† í°

2. listing_type_confidence: ìœ í˜• íŒë‹¨ ì‹ ë¢°ë„ (0.0 ~ 1.0)

3. risk_level: ë¦¬ìŠ¤í¬ ë ˆë²¨
   - "low": ë¦¬ìŠ¤í¬ ë‚®ìŒ
   - "medium": ë³´í†µ
   - "high": ì£¼ì˜ í•„ìš”
   - "critical": ë§¤ìš° ìœ„í—˜

4. risk_factors: ë¦¬ìŠ¤í¬ ìš”ì†Œ ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 3ê°œ)

5. supply_pressure: ê³µê¸‰ ì••ë ¥
   - "smooth": ì›í™œ (ë§¤ë„ ì••ë ¥ ë‚®ìŒ, í¥ë”°ë¦¬ ìœ ë ¥)
   - "moderate": ë³´í†µ
   - "tight": ê³µê¸‰ ì••ë°• (ì—ì–´ë“œë/ì–¸ë½ ë¬¼ëŸ‰, ë§ë”°ë¦¬ ì£¼ì˜)
   - "unknown": íŒë‹¨ ë¶ˆê°€

6. supply_reasoning: ê³µê¸‰ ì••ë ¥ íŒë‹¨ ê·¼ê±° (1ë¬¸ì¥)

7. summary: í•µì‹¬ ìš”ì•½ (1ë¬¸ì¥, í•œêµ­ì–´)

8. warnings: ì£¼ì˜ì‚¬í•­ ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 2ê°œ, í•œêµ­ì–´)

JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´."""
    
    def _build_prompt(self, text: str, exchange: str, symbol: str | None) -> str:
        """ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±."""
        symbol_info = f"í† í°: {symbol}" if symbol else ""
        
        return f"""ë‹¤ìŒ {exchange.upper()} ê±°ë˜ì†Œ ê³µì‹œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

{symbol_info}

ê³µì‹œ ë‚´ìš©:
---
{text[:3000]}
---

ìœ„ ê³µì‹œë¥¼ ë¶„ì„í•˜ê³  JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì„¸ìš”."""
    
    def _parse_response(
        self, 
        content: str, 
        model: str, 
        tokens: int, 
        duration_ms: float
    ) -> AIAnalysisResult:
        """AI ì‘ë‹µ íŒŒì‹±."""
        try:
            # JSON ì¶”ì¶œ (```json ... ``` í˜•íƒœ ì²˜ë¦¬)
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]
            
            data = json.loads(content.strip())
            
            return AIAnalysisResult(
                listing_type=data.get("listing_type", "UNKNOWN"),
                listing_type_confidence=float(data.get("listing_type_confidence", 0.5)),
                risk_level=ListingRisk(data.get("risk_level", "medium")),
                risk_factors=data.get("risk_factors", [])[:3],
                supply_pressure=SupplyPressure(data.get("supply_pressure", "unknown")),
                supply_reasoning=data.get("supply_reasoning", ""),
                summary=data.get("summary", ""),
                warnings=data.get("warnings", [])[:2],
                model_used=model,
                tokens_used=tokens,
                analysis_time_ms=duration_ms,
                raw_response=data,
            )
            
        except Exception as e:
            logger.warning("[AIAnalyzer] ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: %s", e)
            
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return AIAnalysisResult(
                listing_type="UNKNOWN",
                listing_type_confidence=0.3,
                risk_level=ListingRisk.MEDIUM,
                risk_factors=["íŒŒì‹± ì‹¤íŒ¨"],
                supply_pressure=SupplyPressure.UNKNOWN,
                supply_reasoning="AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨",
                summary="ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                warnings=["AI ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜"],
                model_used=model,
                tokens_used=tokens,
                analysis_time_ms=duration_ms,
            )


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_analyzer: AIAnalyzer | None = None


def get_ai_analyzer() -> AIAnalyzer:
    """AI Analyzer ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤."""
    global _analyzer
    if _analyzer is None:
        _analyzer = AIAnalyzer()
    return _analyzer
